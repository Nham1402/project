{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa31043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | Field Name | Data Type | Description (Vietnamese) | Description (English) | Business Rules | Example |\n",
    "# |------------|-----------|--------------------------|----------------------|----------------|---------|\n",
    "# | transaction_key | int | Kh√≥a ch√≠nh surrogate | Primary surrogate key | PK, NOT NULL, UNIQUE | 1001 |\n",
    "# | customer_key | int | Kh√≥a kh√°ch h√†ng | Customer foreign key | FK to DIM_CUSTOMER | 12345 |\n",
    "# | product_key | int | Kh√≥a s·∫£n ph·∫©m | Product foreign key | FK to DIM_PRODUCT | 567 |\n",
    "# | location_key | int | Kh√≥a ƒë·ªãa ƒëi·ªÉm | Location foreign key | FK to DIM_LOCATION | 789 |\n",
    "# | event_key | int | Kh√≥a s·ª± ki·ªán | Event foreign key | FK to DIM_EVENT | 101 |\n",
    "# | involved_party_key | int | Kh√≥a b√™n li√™n quan | Involved party foreign key | FK to DIM_INVOLVED_PARTY | 234 |\n",
    "# | condition_key | int | Kh√≥a ƒëi·ªÅu ki·ªán | Condition foreign key | FK to DIM_CONDITION | 345 |\n",
    "# | application_key | int | Kh√≥a ·ª©ng d·ª•ng | Application foreign key | FK to DIM_APPLICATION | 456 |\n",
    "# | asset_key | int | Kh√≥a t√†i s·∫£n | Asset foreign key | FK to DIM_ASSET | 678 |\n",
    "#------------------------------------------------------------------\n",
    "#    KEY \n",
    "#------------------------------------------------------------------\n",
    "# | transaction_id | string | M√£ giao d·ªãch duy nh·∫•t | Unique transaction ID | NOT NULL, UNIQUE | TXN20240315143025001 |\n",
    "# | reference_number | string | S·ªë tham chi·∫øu | Reference number | Max 50 chars | REF123456789 |\n",
    "# | transaction_type | string | Lo·∫°i giao d·ªãch | Transaction type | NOT NULL | Chuy·ªÉn kho·∫£n, R√∫t ti·ªÅn, N·∫°p ti·ªÅn,  Nh·∫≠n Ti·ªÅn |\n",
    "# | transaction_category | string | Danh m·ª•c giao d·ªãch | Transaction category | NOT NULL | N·ªôi b·ªô, Li√™n ng√¢n h√†ng, Qu·ªëc t·∫ø |\n",
    "# | transaction_subcategory | string | Danh m·ª•c ph·ª• | Transaction subcategory | Max 100 chars | Chuy·ªÉn kho·∫£n c√πng ng√¢n h√†ng |\n",
    "# | transaction_amount | decimal | S·ªë ti·ªÅn giao d·ªãch | Transaction amount | NOT NULL, >= 0 | 1000000 |\n",
    "# | fee_amount | decimal | Ph√≠ giao d·ªãch | Fee amount | >= 0 | 11000 |\n",
    "# | tax_amount | decimal | Thu·∫ø | Tax amount | >= 0 | 1100 |\n",
    "# | net_amount | decimal | S·ªë ti·ªÅn th·ª±c nh·∫≠n | Net amount | NOT NULL | 987900 |\n",
    "# | currency | string | Lo·∫°i ti·ªÅn t·ªá | Currency code | ISO 4217, NOT NULL | VND |\n",
    "# | transaction_status | string | Tr·∫°ng th√°i giao d·ªãch | Transaction status | NOT NULL | Th√†nh c√¥ng, Th·∫•t b·∫°i, ƒêang x·ª≠ l√Ω |\n",
    "# | channel | string | K√™nh giao d·ªãch | Transaction channel | NOT NULL | ATM, Mobile App, Internet Banking |\n",
    "# | description | string | M√¥ t·∫£ giao d·ªãch | Transaction description | Max 500 chars | Chuy·ªÉn kho·∫£n cho thu√™ nh√† |\n",
    "# | created_timestamp | timestamp | Th·ªùi gian t·∫°o | Creation timestamp | NOT NULL | 2024-03-15 14:30:25.123 |\n",
    "# | processed_timestamp | timestamp | Th·ªùi gian x·ª≠ l√Ω | Processing timestamp | >= created_timestamp | 2024-03-15 14:30:27.456 |\n",
    "# | updated_timestamp | timestamp | Th·ªùi gian c·∫≠p nh·∫≠t cu·ªëi | Last update timestamp | >= created_timestamp | 2024-03-15 14:31:00.789 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30857e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539df278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_30780\\3678611362.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account_key': 15, 'customer_key': 7, 'location_key': 5, 'event_key': 16635940198104253731, 'application_key': 16, 'transaction_id': 'TXN20250904171810663', 'reference_number': 'REF944C96BAD0', 'transaction_type': 'R√∫t ti·ªÅn', 'transaction_category': 'N·ªôi b·ªô', 'transaction_amount': 6269738.14, 'fee_amount': 31681.51, 'tax_amount': 3168.15, 'net_amount': 0.0, 'currency': 'VND', 'account_number': '263bd9d371194', 'transaction_status': 'Th·∫•t b·∫°i', 'channel': 'ATM', 'description': 'Giao d·ªãch R√∫t ti·ªÅn qua ATM', 'created_timestamp': datetime.datetime(2025, 9, 4, 17, 18, 10, 873244), 'processed_timestamp': datetime.datetime(2025, 9, 4, 17, 19, 26, 873244), 'updated_timestamp': datetime.datetime(2025, 9, 4, 17, 20, 23, 873244)}\n",
      "{'account_key': 40, 'customer_key': 19, 'location_key': 5, 'event_key': 13161864128149406645, 'application_key': 14, 'transaction_id': 'TXN20250904171811805', 'reference_number': 'REF0275686E17', 'transaction_type': 'N·∫°p ti·ªÅn', 'transaction_category': 'Qu·ªëc t·∫ø', 'transaction_amount': 4096640.13, 'fee_amount': 16093.09, 'tax_amount': 1609.31, 'net_amount': 0.0, 'currency': 'VND', 'account_number': 'QT917000', 'transaction_status': 'Th·∫•t b·∫°i', 'channel': 'Mobile App', 'description': 'Giao d·ªãch N·∫°p ti·ªÅn qua Mobile App', 'created_timestamp': datetime.datetime(2025, 9, 4, 17, 18, 11, 57805), 'processed_timestamp': datetime.datetime(2025, 9, 4, 17, 19, 41, 57805), 'updated_timestamp': datetime.datetime(2025, 9, 4, 17, 23, 11, 57805)}\n",
      "{'account_key': 40, 'customer_key': 19, 'location_key': 8, 'event_key': 8193574250190226994, 'application_key': 41, 'transaction_id': 'TXN20250904171811401', 'reference_number': 'REF09B9ED47AE', 'transaction_type': 'Chuy·ªÉn kho·∫£n', 'transaction_category': 'Li√™n ng√¢n h√†ng', 'transaction_amount': 238754.23, 'fee_amount': 1849.91, 'tax_amount': 184.99, 'net_amount': 0.0, 'currency': 'VND', 'account_number': 'LB223103', 'transaction_status': 'Th·∫•t b·∫°i', 'channel': 'Internet Banking', 'description': 'Giao d·ªãch Chuy·ªÉn kho·∫£n qua Internet Banking', 'created_timestamp': datetime.datetime(2025, 9, 4, 17, 18, 11, 269176), 'processed_timestamp': datetime.datetime(2025, 9, 4, 17, 20, 17, 269176), 'updated_timestamp': datetime.datetime(2025, 9, 4, 17, 21, 55, 269176)}\n",
      "{'account_key': 15, 'customer_key': 7, 'location_key': 8, 'event_key': 6582257374910300642, 'application_key': 8, 'transaction_id': 'TXN20250904171811741', 'reference_number': 'REF9FF4778EDB', 'transaction_type': 'Chuy·ªÉn kho·∫£n', 'transaction_category': 'Li√™n ng√¢n h√†ng', 'transaction_amount': 5132554.79, 'fee_amount': 9017.07, 'tax_amount': 901.71, 'net_amount': 0.0, 'currency': 'VND', 'account_number': 'LB250689', 'transaction_status': 'Th·∫•t b·∫°i', 'channel': 'Internet Banking', 'description': 'Giao d·ªãch Chuy·ªÉn kho·∫£n qua Internet Banking', 'created_timestamp': datetime.datetime(2025, 9, 4, 17, 18, 11, 505213), 'processed_timestamp': datetime.datetime(2025, 9, 4, 17, 21, 51, 505213), 'updated_timestamp': datetime.datetime(2025, 9, 4, 17, 26, 49, 505213)}\n",
      "{'account_key': 16, 'customer_key': 7, 'location_key': 8, 'event_key': 9650783426557658554, 'application_key': 43, 'transaction_id': 'TXN20250904171811748', 'reference_number': 'REFDA2BE242C9', 'transaction_type': 'Nh·∫≠n Ti·ªÅn', 'transaction_category': 'N·ªôi b·ªô', 'transaction_amount': 6557175.85, 'fee_amount': 37965.98, 'tax_amount': 3796.6, 'net_amount': 6557176, 'currency': 'VND', 'account_number': '82d592e7931e4', 'transaction_status': 'Th√†nh c√¥ng', 'channel': 'Internet Banking', 'description': 'Giao d·ªãch Nh·∫≠n Ti·ªÅn qua Internet Banking', 'created_timestamp': datetime.datetime(2025, 9, 4, 17, 18, 11, 714440), 'processed_timestamp': datetime.datetime(2025, 9, 4, 17, 18, 54, 714440), 'updated_timestamp': datetime.datetime(2025, 9, 4, 17, 19, 22, 714440)}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "import uuid\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class getInfoTransaction:\n",
    "    def __init__(self, conn_params):\n",
    "        self.engine = create_engine(\n",
    "            f\"postgresql+psycopg2://{conn_params['user']}:{conn_params['password']}@{conn_params['host']}:{conn_params['port']}/{conn_params['dbname']}\"\n",
    "        )\n",
    "\n",
    "    def _query(self, sql: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            conn = self.engine.raw_connection()   \n",
    "            try:\n",
    "                df = pd.read_sql_query(sql, conn)\n",
    "            finally:\n",
    "                conn.close()  \n",
    "            return df\n",
    "        except Exception as e:  \n",
    "            print(f\"Error executing query: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def getCustomer(self):\n",
    "        df = self._query(\"SELECT customer_key FROM banking_dw.dim_customer\")\n",
    "        return df\n",
    "\n",
    "    def getLocation(self):\n",
    "        df = self._query(\"SELECT location_key   FROM banking_dw.dim_location\")\n",
    "        return df\n",
    "\n",
    "    def getApplication(self):\n",
    "        df = self._query(\"SELECT application_key FROM banking_dw.dim_application\")\n",
    "        return df\n",
    "\n",
    "    def getAccount(self):\n",
    "        df = self._query(\"SELECT account_key , account_number , customer_key , current_balance FROM banking_dw.dim_account\")\n",
    "        return df\n",
    "\n",
    "class GenerationTranaction :\n",
    "    def __init__(self , conn_params):\n",
    "        self.conn_params = conn_params\n",
    "        self.account = getInfoTransaction(conn_params).getAccount()\n",
    "        self.location = getInfoTransaction(conn_params).getLocation()\n",
    "        self.application = getInfoTransaction(conn_params).getApplication()\n",
    "        self.transaction_types = [\"Chuy·ªÉn kho·∫£n\", \"R√∫t ti·ªÅn\", \"N·∫°p ti·ªÅn\", \"Nh·∫≠n Ti·ªÅn\"]\n",
    "        self.transaction_category = [\"N·ªôi b·ªô\", \"Li√™n ng√¢n h√†ng\", \"Qu·ªëc t·∫ø\"]\n",
    "        self.transaction_status = [\"Th√†nh c√¥ng\", \"Th·∫•t b·∫°i\"]\n",
    "        self.channel = [\"ATM\", \"Mobile App\", \"Internet Banking\"]\n",
    "        \n",
    "    def get_customer_key(self , account_key):\n",
    "        df = self.account[self.account[\"account_key\"] == account_key]\n",
    "        if not df.empty:\n",
    "            return df.iloc[0][\"customer_key\"]\n",
    "        return None\n",
    "    \n",
    "    # tinh tien net nhan duoc khi thuc hien giao dich\n",
    "    def amount(self ,transaction_types , transaction_status,  transaction_amount , fee_amount , tax_amount , ):\n",
    "        if transaction_status == \"Th·∫•t b·∫°i\":\n",
    "            return 0.0\n",
    "        else:\n",
    "            if transaction_types == \"R√∫t ti·ªÅn\":\n",
    "                return round(transaction_amount + fee_amount + tax_amount , 2)\n",
    "            elif transaction_types == \"N·∫°p ti·ªÅn\":\n",
    "                return round(transaction_amount)\n",
    "            elif transaction_types == \"Chuy·ªÉn kho·∫£n\":  \n",
    "                return  round(transaction_amount + fee_amount + tax_amount , 2)\n",
    "            elif transaction_types == \"Nh·∫≠n Ti·ªÅn\":\n",
    "                return round(transaction_amount)\n",
    "        \n",
    "        \n",
    "    def transaction_account_number(self , transaction_category ):\n",
    "        if transaction_category == \"N·ªôi b·ªô\":\n",
    "            return random.choice(self.account[\"account_number\"])\n",
    "        elif transaction_category == \"Li√™n ng√¢n h√†ng\":\n",
    "            return f\"LB{random.randint(100000, 999999)}\"\n",
    "        elif transaction_category == \"Qu·ªëc t·∫ø\":\n",
    "            return f\"QT{random.randint(100000, 999999)}\"\n",
    "        \n",
    "    def generator_data_transaction(self):\n",
    "        \n",
    "        account_key   =  int(random.choice(self.account[\"account_key\"]))\n",
    "        customer_key  =  int(self.get_customer_key(account_key))\n",
    "        location_key  =  int(random.choice(self.location[\"location_key\"]))\n",
    "        event_key = uuid.uuid4().int >> 64\n",
    "        application_key = int(random.choice(self.account[\"account_key\"]))\n",
    "        transaction_id = f\"TXN{datetime.now().strftime('%Y%m%d%H%M%S')}{random.randint(100, 999)}\"\n",
    "        reference_number = f\"REF{uuid.uuid4().hex[:10].upper()}\"\n",
    "        transaction_type = random.choice(self.transaction_types)\n",
    "        transaction_category = random.choice(self.transaction_category)\n",
    "        transaction_amount = round(random.uniform(10000, 10000000), 2)\n",
    "        transaction_status = random.choice(self.transaction_status)\n",
    "        fee_amount = round(transaction_amount * random.uniform(0.001, 0.01), 2)\n",
    "        tax_amount = round(fee_amount * 0.1, 2)\n",
    "        net_amount = self.amount(transaction_type,transaction_status,transaction_amount, fee_amount, tax_amount) \n",
    "        currency = \"VND\"\n",
    "        account_number = self.transaction_account_number(transaction_category)\n",
    "\n",
    "        channel = random.choice(self.channel)\n",
    "        description = f\"Giao d·ªãch {transaction_type} qua {channel}\"\n",
    "        created_timestamp = datetime.now()\n",
    "        processed_timestamp = created_timestamp + timedelta(seconds=random.randint(1, 300))\n",
    "        updated_timestamp = processed_timestamp + timedelta(seconds=random.randint(1, 300))\n",
    "\n",
    "        \n",
    "        return {\n",
    "            \"account_key\": account_key,\n",
    "            \"customer_key\": customer_key,\n",
    "            \"location_key\": location_key,\n",
    "            \"event_key\": event_key,\n",
    "            \"application_key\": application_key,\n",
    "            \"transaction_id\": transaction_id,\n",
    "            \"reference_number\": reference_number,\n",
    "            \"transaction_type\": transaction_type,\n",
    "            \"transaction_category\": transaction_category,\n",
    "            \"transaction_amount\": transaction_amount,\n",
    "            \"fee_amount\": fee_amount,\n",
    "            \"tax_amount\": tax_amount,\n",
    "            \"net_amount\": net_amount,\n",
    "            \"currency\": currency,\n",
    "            \"account_number\": account_number,\n",
    "            \"transaction_status\": transaction_status,\n",
    "            \"channel\": channel,\n",
    "            \"description\": description,\n",
    "            \"created_timestamp\": created_timestamp,\n",
    "            \"processed_timestamp\": processed_timestamp,\n",
    "            \"updated_timestamp\": updated_timestamp\n",
    "        }\n",
    "          \n",
    "if __name__ == \"__main__\":  \n",
    "    load_dotenv()\n",
    "    \n",
    "    conn_params = {\n",
    "        \"host\": os.getenv(\"DB_HOST\"),\n",
    "        \"port\": os.getenv(\"DB_PORT\"),\n",
    "        \"dbname\": os.getenv(\"DB_NAME\"),\n",
    "        \"user\": os.getenv(\"DB_USER\"),\n",
    "        \"password\": os.getenv(\"DB_PASS\")\n",
    "    }\n",
    "    info_transaction = GenerationTranaction(conn_params)\n",
    "    print(info_transaction.generator_data_transaction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd2233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 22:17:19,778 - __main__ - INFO - üîß Database: jdbc:postgresql://192.168.235.136:5432/dwh\n",
      "2025-09-08 22:17:19,778 - __main__ - INFO - üîß Table: banking_dw.fact_transaction\n",
      "2025-09-08 22:17:19,779 - __main__ - INFO - üöÄ STARTING REALTIME KAFKA TO POSTGRES STREAMING\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'JavaPackage' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 183\u001b[0m\n\u001b[0;32m    180\u001b[0m     realtime_stream\u001b[38;5;241m.\u001b[39mstart_realtime_processing()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 183\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 179\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    178\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müöÄ STARTING REALTIME KAFKA TO POSTGRES STREAMING\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 179\u001b[0m     realtime_stream \u001b[38;5;241m=\u001b[39m \u001b[43mRealtimeSparkStreaming\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     realtime_stream\u001b[38;5;241m.\u001b[39mstart_realtime_processing()\n",
      "Cell \u001b[1;32mIn[4], line 122\u001b[0m, in \u001b[0;36mRealtimeSparkStreaming.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRealtimeKafkaToPostgres\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal[*]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.executor.memory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.executor.cores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.driver.memory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.shuffle.partitions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.adaptive.enabled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.serializer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.spark.serializer.KryoSerializer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.execution.arrow.pyspark.enabled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.streaming.forceDeleteTempCheckpointLocation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39msparkContext\u001b[38;5;241m.\u001b[39msetLogLevel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö° Spark session created for realtime processing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\sql\\session.py:559\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    556\u001b[0m     sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39mgetOrCreate(sparkConf)\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m--> 559\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    561\u001b[0m     module \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39m_get_j_spark_session_module(session\u001b[38;5;241m.\u001b[39m_jvm)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\sql\\session.py:635\u001b[0m, in \u001b[0;36mSparkSession.__init__\u001b[1;34m(self, sparkContext, jsparkSession, options)\u001b[0m\n\u001b[0;32m    631\u001b[0m jSparkSessionModule \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39m_get_j_spark_session_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jsparkSession \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m--> 635\u001b[0m         \u001b[43mjSparkSessionClass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetDefaultSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39misDefined()\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jSparkSessionClass\u001b[38;5;241m.\u001b[39mgetDefaultSession()\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39msparkContext()\u001b[38;5;241m.\u001b[39misStopped()\n\u001b[0;32m    637\u001b[0m     ):\n\u001b[0;32m    638\u001b[0m         jsparkSession \u001b[38;5;241m=\u001b[39m jSparkSessionClass\u001b[38;5;241m.\u001b[39mgetDefaultSession()\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m    639\u001b[0m         jSparkSessionModule\u001b[38;5;241m.\u001b[39mapplyModifiableSettings(jsparkSession, options)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'JavaPackage' object is not callable"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "# ===============================\n",
    "# Logging setup\n",
    "# ===============================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables (.env ƒë·∫∑t ngo√†i project/consumer)\n",
    "load_dotenv(dotenv_path=os.path.join(\"/home/hadoop/project\", \".env\"))\n",
    "\n",
    "# ===============================\n",
    "# Config\n",
    "# ===============================\n",
    "KAFKA_CONFIG = {\n",
    "    'bootstrap.servers': '192.168.235.136:9092,192.168.235.147:9092,192.168.235.148:9092',\n",
    "}\n",
    "\n",
    "POSTGRES_CONFIG = {\n",
    "    \"url\": f\"jdbc:postgresql://{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\",\n",
    "    \"table\": \"banking_dw.fact_transaction\",\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASS\"),\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "logger.info(f\"üîß Database: {POSTGRES_CONFIG['url']}\")\n",
    "logger.info(f\"üîß Table: {POSTGRES_CONFIG['table']}\")\n",
    "\n",
    "# ===============================\n",
    "# Schema kh·ªõp v·ªõi b·∫£ng fact_transaction\n",
    "# ===============================\n",
    "TRANSACTION_SCHEMA = StructType([\n",
    "    StructField(\"account_key\", IntegerType(), True),\n",
    "    StructField(\"customer_key\", IntegerType(), True),\n",
    "    StructField(\"location_key\", IntegerType(), True),\n",
    "    StructField(\"event_key\", IntegerType(), True),\n",
    "    StructField(\"application_key\", IntegerType(), True),\n",
    "    StructField(\"transaction_id\", StringType(), True),\n",
    "    StructField(\"reference_number\", StringType(), True),\n",
    "    StructField(\"transaction_type\", StringType(), True),\n",
    "    StructField(\"transaction_category\", StringType(), True),\n",
    "    StructField(\"transaction_amount\", DoubleType(), True),\n",
    "    StructField(\"transaction_status\", StringType(), True),\n",
    "    StructField(\"fee_amount\", DoubleType(), True),\n",
    "    StructField(\"tax_amount\", DoubleType(), True),\n",
    "    StructField(\"net_amount\", DoubleType(), True),\n",
    "    StructField(\"currency\", StringType(), True),\n",
    "    StructField(\"account_number\", StringType(), True),\n",
    "    StructField(\"channel\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"created_timestamp\", TimestampType(), True),\n",
    "    StructField(\"processed_timestamp\", TimestampType(), True),\n",
    "    StructField(\"updated_timestamp\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# ===============================\n",
    "# Realtime Write Function\n",
    "# ===============================\n",
    "def write_realtime_batch(batch_df, batch_id):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        row_count = batch_df.count()\n",
    "        logger.info(f\"‚ö° Batch {batch_id}: Processing {row_count} records\")\n",
    "\n",
    "        if row_count == 0:\n",
    "            return\n",
    "\n",
    "        # Validate: transaction_id + transaction_amount ph·∫£i c√≥\n",
    "        valid_df = batch_df.filter(\n",
    "            col(\"transaction_id\").isNotNull() &\n",
    "            col(\"transaction_amount\").isNotNull() &\n",
    "            (col(\"transaction_amount\") > 0)\n",
    "        )\n",
    "\n",
    "        valid_count = valid_df.count()\n",
    "        if valid_count == 0:\n",
    "            logger.warning(f\"‚ö° Batch {batch_id}: No valid records\")\n",
    "            return\n",
    "\n",
    "        # Add processing timestamp\n",
    "        final_df = valid_df.withColumn(\"realtime_processed_at\", current_timestamp())\n",
    "\n",
    "        # Write to PostgreSQL\n",
    "        final_df.write \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .option(\"url\", POSTGRES_CONFIG[\"url\"]) \\\n",
    "            .option(\"dbtable\", POSTGRES_CONFIG[\"table\"]) \\\n",
    "            .option(\"user\", POSTGRES_CONFIG[\"user\"]) \\\n",
    "            .option(\"password\", POSTGRES_CONFIG[\"password\"]) \\\n",
    "            .option(\"driver\", POSTGRES_CONFIG[\"driver\"]) \\\n",
    "            .option(\"batchsize\", \"500\") \\\n",
    "            .option(\"isolationLevel\", \"READ_UNCOMMITTED\") \\\n",
    "            .option(\"numPartitions\", \"1\") \\\n",
    "            .option(\"rewriteBatchedStatements\", \"true\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()\n",
    "\n",
    "        processing_time = time.time() - start_time\n",
    "        logger.info(f\"‚úÖ Batch {batch_id}: Inserted {valid_count} records in {processing_time:.2f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        processing_time = time.time() - start_time\n",
    "        logger.error(f\"‚ùå Batch {batch_id} failed after {processing_time:.2f}s: {e}\")\n",
    "        logger.error(f\"‚ùå Error details: {traceback.format_exc()}\")\n",
    "\n",
    "# ===============================\n",
    "# Realtime Streaming Class\n",
    "# ===============================\n",
    "class RealtimeSparkStreaming:\n",
    "    def __init__(self):\n",
    "        self.spark = SparkSession.builder \\\n",
    "            .appName(\"RealtimeKafkaToPostgres\") \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .config(\"spark.executor.memory\", \"2g\") \\\n",
    "            .config(\"spark.executor.cores\", \"2\") \\\n",
    "            .config(\"spark.driver.memory\", \"1g\") \\\n",
    "            .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "            .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "            .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "            .config(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\") \\\n",
    "            .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.2,org.postgresql:postgresql:42.2.18\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        self.spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "        logger.info(\"‚ö° Spark session created for realtime processing\")\n",
    "\n",
    "    def create_realtime_stream(self):\n",
    "        logger.info(\"‚ö° Creating realtime Kafka stream...\")\n",
    "\n",
    "        kafka_df = self.spark.readStream \\\n",
    "            .format(\"kafka\") \\\n",
    "            .option(\"kafka.bootstrap.servers\", KAFKA_CONFIG['bootstrap.servers']) \\\n",
    "            .option(\"subscribe\", \"transaction_data\") \\\n",
    "            .option(\"startingOffsets\", \"latest\") \\\n",
    "            .option(\"failOnDataLoss\", \"false\") \\\n",
    "            .option(\"maxOffsetsPerTrigger\", \"1000\") \\\n",
    "            .option(\"kafka.consumer.cache.enabled\", \"false\") \\\n",
    "            .load()\n",
    "\n",
    "        parsed_df = kafka_df.select(\n",
    "            col(\"key\").cast(\"string\"),\n",
    "            from_json(col(\"value\").cast(\"string\"), TRANSACTION_SCHEMA).alias(\"data\"),\n",
    "            col(\"timestamp\").alias(\"kafka_timestamp\")\n",
    "        ).select(\"key\", \"data.*\", \"kafka_timestamp\")\n",
    "\n",
    "        parsed_df.printSchema()\n",
    "        logger.info(\"‚úÖ Realtime Kafka stream created successfully\")\n",
    "        return parsed_df\n",
    "\n",
    "    def start_realtime_processing(self):\n",
    "        df = self.create_realtime_stream()\n",
    "\n",
    "        query = df.writeStream \\\n",
    "            .foreachBatch(write_realtime_batch) \\\n",
    "            .outputMode(\"append\") \\\n",
    "            .option(\"checkpointLocation\", \"/tmp/realtime_checkpoint\") \\\n",
    "            .trigger(processingTime=\"2 seconds\") \\\n",
    "            .start()\n",
    "\n",
    "        logger.info(\"‚ö° REALTIME PROCESSING STARTED!\")\n",
    "        query.awaitTermination()\n",
    "\n",
    "# ===============================\n",
    "# Main Function\n",
    "# ===============================\n",
    "def main():\n",
    "    logger.info(\"üöÄ STARTING REALTIME KAFKA TO POSTGRES STREAMING\")\n",
    "    realtime_stream = RealtimeSparkStreaming()\n",
    "    realtime_stream.start_realtime_processing()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e5ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
